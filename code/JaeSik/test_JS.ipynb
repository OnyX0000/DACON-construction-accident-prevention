{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e50eee59-b527-44e0-afa8-7e4ee190affb",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493a074b-5e32-44c1-aee9-d378b1b37003",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Module langchain_community.embeddings not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\DACON_PREDICTION\\.env311\\Lib\\site-packages\\langchain\\_api\\module_import.py:69\u001b[0m, in \u001b[0;36mcreate_importer.<locals>.import_by_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "File \u001b[1;32mc:\\DACON_PREDICTION\\.env311\\Lib\\site-packages\\langchain\\embeddings\\__init__.py:167\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Look up attributes dynamically.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\DACON_PREDICTION\\.env311\\Lib\\site-packages\\langchain\\_api\\module_import.py:72\u001b[0m, in \u001b[0;36mcreate_importer.<locals>.import_by_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_module\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_community\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 72\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install langchain-community to access this module. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can install it using `pip install -U langchain-community`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: Module langchain_community.embeddings not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f4223e-111b-49a8-a716-5f98caacf12f",
   "metadata": {},
   "source": [
    "# Data Load & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f871264a-ecd6-430d-ab1f-8edad746bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', encoding = 'utf-8-sig')\n",
    "test = pd.read_csv('./data/test.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcc0921-e9a7-407a-a070-148abb06aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "train['공사종류(대분류)'] = train['공사종류'].str.split(' / ').str[0]\n",
    "train['공사종류(중분류)'] = train['공사종류'].str.split(' / ').str[1]\n",
    "train['공종(대분류)'] = train['공종'].str.split(' > ').str[0]\n",
    "train['공종(중분류)'] = train['공종'].str.split(' > ').str[1]\n",
    "train['사고객체(대분류)'] = train['사고객체'].str.split(' > ').str[0]\n",
    "train['사고객체(중분류)'] = train['사고객체'].str.split(' > ').str[1]\n",
    "\n",
    "test['공사종류(대분류)'] = test['공사종류'].str.split(' / ').str[0]\n",
    "test['공사종류(중분류)'] = test['공사종류'].str.split(' / ').str[1]\n",
    "test['공종(대분류)'] = test['공종'].str.split(' > ').str[0]\n",
    "test['공종(중분류)'] = test['공종'].str.split(' > ').str[1]\n",
    "test['사고객체(대분류)'] = test['사고객체'].str.split(' > ').str[0]\n",
    "test['사고객체(중분류)'] = test['사고객체'].str.split(' > ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e51bca-0c93-4412-9634-9f86ea9a36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 통합 생성\n",
    "combined_training_data = train.apply(\n",
    "    lambda row: {\n",
    "        \"question\": (\n",
    "            f\"공사종류 대분류 '{row['공사종류(대분류)']}', 중분류 '{row['공사종류(중분류)']}' 공사 중 \"\n",
    "            f\"공종 대분류 '{row['공종(대분류)']}', 중분류 '{row['공종(중분류)']}' 작업에서 \"\n",
    "            f\"사고객체 '{row['사고객체(대분류)']}'(중분류: '{row['사고객체(중분류)']}')와 관련된 사고가 발생했습니다. \"\n",
    "            f\"작업 프로세스는 '{row['작업프로세스']}'이며, 사고 원인은 '{row['사고원인']}'입니다. \"\n",
    "            f\"재발 방지 대책 및 향후 조치 계획은 무엇인가요?\"\n",
    "        ),\n",
    "        \"answer\": row[\"재발방지대책 및 향후조치계획\"]\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# DataFrame으로 변환\n",
    "combined_training_data = pd.DataFrame(list(combined_training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf53249-8aae-4308-a476-4200814da53d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 통합 생성\n",
    "combined_test_data = test.apply(\n",
    "    lambda row: {\n",
    "        \"question\": (\n",
    "            f\"공사종류 대분류 '{row['공사종류(대분류)']}', 중분류 '{row['공사종류(중분류)']}' 공사 중 \"\n",
    "            f\"공종 대분류 '{row['공종(대분류)']}', 중분류 '{row['공종(중분류)']}' 작업에서 \"\n",
    "            f\"사고객체 '{row['사고객체(대분류)']}'(중분류: '{row['사고객체(중분류)']}')와 관련된 사고가 발생했습니다. \"\n",
    "            f\"작업 프로세스는 '{row['작업프로세스']}'이며, 사고 원인은 '{row['사고원인']}'입니다. \"\n",
    "            f\"재발 방지 대책 및 향후 조치 계획은 무엇인가요?\"\n",
    "        )\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# DataFrame으로 변환\n",
    "combined_test_data = pd.DataFrame(list(combined_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bea209-6521-4974-a785-c2faf5af427c",
   "metadata": {},
   "source": [
    "# Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b1d4ec-a335-4a3e-803e-1ee0a8e8b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd9f2e5-4293-48b1-9c8a-347cf500b257",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCSOFT/Llama-VARCO-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, quantization_config\u001b[38;5;241m=\u001b[39mbnb_config, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ff667",
   "metadata": {},
   "source": [
    "# Vector store 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b47aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 데이터 준비\n",
    "train_questions_prevention = combined_training_data['question'].tolist()\n",
    "train_answers_prevention = combined_training_data['answer'].tolist()\n",
    "\n",
    "train_documents = [\n",
    "    f\"Q: {q1}\\nA: {a1}\" \n",
    "    for q1, a1 in zip(train_questions_prevention, train_answers_prevention)\n",
    "]\n",
    "\n",
    "# 임베딩 생성\n",
    "embedding_model_name = \"jhgan/ko-sbert-nli\"  # 임베딩 모델 선택\n",
    "embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# 벡터 스토어에 문서 추가\n",
    "vector_store = FAISS.from_texts(train_documents, embedding)\n",
    "\n",
    "# Retriever 정의\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533fc9f",
   "metadata": {},
   "source": [
    "# RAG chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371d4e9e-fd99-4157-abab-a367a24fa269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,  # sampling 활성화\n",
    "    temperature=0.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=64,\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "### 지침: 당신은 건설 안전 전문가입니다.\n",
    "질문에 대한 답변을 핵심 내용만 요약하여 간략하게 작성하세요.\n",
    "- 서론, 배경 설명 또는 추가 설명을 절대 포함하지 마세요.\n",
    "- 다음과 같은 조치를 취할 것을 제안합니다: 와 같은 내용을 포함하지 마세요.\n",
    "\n",
    "{context}\n",
    "\n",
    "### 질문:\n",
    "{question}\n",
    "\n",
    "[/INST]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "# 커스텀 프롬프트 생성\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "\n",
    "# RAG 체인 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  # 단순 컨텍스트 결합 방식 사용\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}  # 커스텀 프롬프트 적용\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b3640-3968-4c2b-a7d4-30f586fadd66",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "590331a4-75f0-4012-8f45-8f2652772c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 실행 시작... 총 테스트 샘플 수: 964\n",
      "\n",
      "[샘플 1/964] 진행 중...\n",
      "공사종류 대분류 '건축', 중분류 '건축물' 공사 중 공종 대분류 '건축', 중분류 '철근콘크리트공사' 작업에서 사고객체 '건설기계'(중분류: '콘크리트펌프')와 관련된 사고가 발생했습니다. 작업 프로세스는 '타설작업'이며, 사고 원인은 '펌프카 아웃트리거 바닥 고임목을 3단으로 보강 했음에도, 지반 침하(아웃트리거 우측 상부 1개소)가 발생하였고,  좌, 우측 아웃트리거의 펼친 길이가 상이하고 타설 위치가 건물 끝부분 모서리에 위치하여 붐대호스를 최대로 펼치다 보니 장비에 대한 무게중심이 한쪽으로 쏠려 일부 전도되는 사고가 발생된 것으로 판단됨'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "사고 원인 분석 결과, 아웃트리거 보강의 부족과 지반 침하, 아웃트리거의 불균형한 펼침, 무게중심의 불균형 등이 사고 원인으로 작용했다고 판단됩니다.\n",
      "\n",
      "재 \n",
      "\n",
      "\n",
      "[샘플 2/964] 진행 중...\n",
      "공사종류 대분류 '건축', 중분류 '건축물' 공사 중 공종 대분류 '건축', 중분류 '수장공사' 작업에서 사고객체 '건설공구'(중분류: '공구류')와 관련된 사고가 발생했습니다. 작업 프로세스는 '절단작업'이며, 사고 원인은 '작업자의 불안전한 행동(숫돌 측면 사용) 및 보안면 미 착용'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "1. 절단기 사용 시 안전 교육 강화: 작업자들에게 절단기 안전사용법과 안전장비 착용의 중요성에 대해 철저히 교육해야 합니다.\n",
      "2. 안전장비 착용 강제화: 절단 작업 시 반드시 보안면 \n",
      "\n",
      "\n",
      "[샘플 3/964] 진행 중...\n",
      "공사종류 대분류 '건축', 중분류 '건축물' 공사 중 공종 대분류 '건축', 중분류 '미장공사' 작업에서 사고객체 '기타'(중분류: '기타')와 관련된 사고가 발생했습니다. 작업 프로세스는 '이동'이며, 사고 원인은 '작업자가 작업을 위해 이동 중 전방을 주시하지 않아 발을 헛디뎌 계단에서 굴러 넘어짐'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "1. 미장공사 작업 중 주의가 필요한 계단 이동 경로를 명확히 표시하고, 근로자들에게 전방 주시의 중요성을 강조하는 안전 교육을 실시합니다.\n",
      "2. 계단 사용 시 안전모를 착용하도록 권고하고, \n",
      "\n",
      "\n",
      "[샘플 4/964] 진행 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공사종류 대분류 '건축', 중분류 '건축물' 공사 중 공종 대분류 '건축', 중분류 '조적공사' 작업에서 사고객체 '건설자재'(중분류: '자재')와 관련된 사고가 발생했습니다. 작업 프로세스는 '기타'이며, 사고 원인은 '작업 발판 위 벽돌 잔재를 밟고 넘어짐'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "주변 정리 철저, 안전 관리 강화, 작업자 안전 의식 고취를 위한 지속적인 지도 요청이 필요합니다.\n",
      "\n",
      "사고 원인인 '작업 발판 위 벽돌 잔재를 밟고 넘어짐'은 작업장 내 정리정 \n",
      "\n",
      "\n",
      "[샘플 5/964] 진행 중...\n",
      "공사종류 대분류 '토목', 중분류 '교량' 공사 중 공종 대분류 '토목', 중분류 '교량공사' 작업에서 사고객체 '기타'(중분류: '기타')와 관련된 사고가 발생했습니다. 작업 프로세스는 '해체작업'이며, 사고 원인은 '점심식사를 위한 이동시 작업자 부주의로 인한 추락사고 발생'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "1. 작업자에게 점심 휴식 시간에 안전한 이동 경로 및 장소를 교육하고, 사고 예방을 위한 주의사항을 강조하는 안전 교육 실시.\n",
      "2. 작업장 내 안전 시설물(예: 안전 램프, 비상구 등)을 \n",
      "\n",
      "\n",
      "[샘플 6/964] 진행 중...\n",
      "공사종류 대분류 '건축', 중분류 '건축물' 공사 중 공종 대분류 '건축', 중분류 '가설공사' 작업에서 사고객체 '가시설'(중분류: '거푸집')와 관련된 사고가 발생했습니다. 작업 프로세스는 '설치작업'이며, 사고 원인은 '안전발판 설치 미흡 및 작업절차 미준수'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "안전발판 전 수리작업 실시, 작업절차 개정 및 교육 실시, 정기적 안전검사 강화, 작업자별 안전성적평가 실시, 안전관리체계 개선 및 정기적 검토.\n",
      "\n",
      "위 사고의 원인인 '안 \n",
      "\n",
      "\n",
      "[샘플 7/964] 진행 중...\n",
      "공사종류 대분류 '토목', 중분류 '도로' 공사 중 공종 대분류 '토목', 중분류 '관공사 부대공사' 작업에서 사고객체 '기타'(중분류: '지하매설물')와 관련된 사고가 발생했습니다. 작업 프로세스는 '매설작업'이며, 사고 원인은 '* 주원인  : 작업자의 불안전한 행동'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "1. 작업자 교육 강화: 작업자의 안전 의식을 높이기 위해 정기적인 안전 교육을 실시하고, 사고 원인에 대한 심층 이해를 도모해야 합니다.\n",
      "2. 작업 환경 개선: 작업장 내 안전 표지판 설치, 작업 공간 정리 \n",
      "\n",
      "\n",
      "[샘플 8/964] 진행 중...\n",
      "공사종류 대분류 '건축', 중분류 '건축물' 공사 중 공종 대분류 '건축', 중분류 '철골공사' 작업에서 사고객체 '건설자재'(중분류: '철근')와 관련된 사고가 발생했습니다. 작업 프로세스는 '설치작업'이며, 사고 원인은 'TSC GIRDER 조립에 필요한 SPLICE PLATE 설치 중 후두부 부딪힘'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "1. TSC GIRDER 조립 시 SPLICE PLATE 설치 작업의 위험성 평가 실시.\n",
      "2. 작업장비 사용자 교육 강화: 안전장비 착용, 적절한 작업 자세, 안전 거리 유지 등.\n",
      "3. 작업장 내 안전시설 개선 \n",
      "\n",
      "\n",
      "[샘플 9/964] 진행 중...\n",
      "공사종류 대분류 '건축', 중분류 '건축물' 공사 중 공종 대분류 '건축', 중분류 '철근콘크리트공사' 작업에서 사고객체 '가시설'(중분류: '기타 가시설')와 관련된 사고가 발생했습니다. 작업 프로세스는 '조립작업'이며, 사고 원인은 '5층 작업 중 이동식틀비계 작업발판 상부에서 콘크리트 바닥으로 내려올 때 하단을 착각하여 몸의 균형을 잃고 넘어져 오른손으로 콘크리트 바닥면을 짚음'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "\n",
      "안전사고 재발 방지를 위해 다음과 같은 대책을 제안합니다:\n",
      "\n",
      "1. 작업장 내 안전 미비요인 제거: 작업장 내 위험 요인을 철저히 점검하고 제거해야 합니다. 특히 작업대 주변의 각재 배치와 작업 \n",
      "\n",
      "\n",
      "[샘플 10/964] 진행 중...\n",
      "공사종류 대분류 '건축', 중분류 '건축물' 공사 중 공종 대분류 '건축', 중분류 '철골공사' 작업에서 사고객체 '부재'(중분류: '철골부재')와 관련된 사고가 발생했습니다. 작업 프로세스는 '해체작업'이며, 사고 원인은 '201동 B3F 남측 B코아 가설빔 해체 작업 중 가설빔에 오른팔 및 복부 충돌로 통증호소'입니다. 재발 방지 대책 및 향후 조치 계획은 무엇인가요?\n",
      "### 답변:\n",
      "해체 작업 중 안전사고 발생을 최소화하기 위해 다음과 같은 재발 방지 대책과 향후 조치 계획을 제안합니다:\n",
      "\n",
      "1. 작업 전 안전점검 강화: 모든 해체 작업 전 사전 안전점검을 철저히 실시하여 잠재 \n",
      "\n",
      "\n",
      "테스트 실행 완료! 총 결과 수: 10\n"
     ]
    }
   ],
   "source": [
    "# 테스트 실행 및 결과 저장\n",
    "test_results = []\n",
    "\n",
    "print(\"테스트 실행 시작... 총 테스트 샘플 수:\", len(combined_test_data))\n",
    "\n",
    "for idx, row in combined_test_data.iterrows():\n",
    "    # # 50개당 한 번 진행 상황 출력\n",
    "    # if (idx + 1) % 50 == 0 or idx == 0:\n",
    "    #     print(f\"\\n[샘플 {idx + 1}/{len(combined_test_data)}] 진행 중...\")\n",
    "    print(f\"\\n[샘플 {idx + 1}/{len(combined_test_data)}] 진행 중...\")\n",
    "    \n",
    "    # RAG 체인 호출 및 결과 생성\n",
    "    prevention_result = qa_chain.invoke(row['question'])\n",
    "\n",
    "    # 결과 저장\n",
    "    result_text = prevention_result['result']\n",
    "    test_results.append(result_text)\n",
    "    print(row['question'])\n",
    "    print(result_text, \"\\n\")\n",
    "    \n",
    "    # 10개만 출력\n",
    "    if idx == 9:\n",
    "        break\n",
    "\n",
    "print(\"\\n테스트 실행 완료! 총 결과 수:\", len(test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9022911",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "178e21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\deeplearning\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--jhgan--ko-sbert-sts. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 768)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model_name = \"jhgan/ko-sbert-sts\"\n",
    "embedding = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "# 문장 리스트를 입력하여 임베딩 생성\n",
    "pred_embeddings = embedding.encode(test_results)\n",
    "print(pred_embeddings.shape)  # (샘플 개수, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb2896b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['### 답변:\\n사고 원인 분석 결과, 아웃트리거 보강의 부족과 지반 침하, 아웃트리거의 불균형한 펼침, 무게중심의 불균형 등이 사고 원인으로 작용했다고 판단됩니다.\\n\\n재',\n",
       " '### 답변:\\n1. 절단기 사용 시 안전 교육 강화: 작업자들에게 절단기 안전사용법과 안전장비 착용의 중요성에 대해 철저히 교육해야 합니다.\\n2. 안전장비 착용 강제화: 절단 작업 시 반드시 보안면',\n",
       " '### 답변:\\n1. 미장공사 작업 중 주의가 필요한 계단 이동 경로를 명확히 표시하고, 근로자들에게 전방 주시의 중요성을 강조하는 안전 교육을 실시합니다.\\n2. 계단 사용 시 안전모를 착용하도록 권고하고,',\n",
       " \"### 답변:\\n주변 정리 철저, 안전 관리 강화, 작업자 안전 의식 고취를 위한 지속적인 지도 요청이 필요합니다.\\n\\n사고 원인인 '작업 발판 위 벽돌 잔재를 밟고 넘어짐'은 작업장 내 정리정\",\n",
       " '### 답변:\\n1. 작업자에게 점심 휴식 시간에 안전한 이동 경로 및 장소를 교육하고, 사고 예방을 위한 주의사항을 강조하는 안전 교육 실시.\\n2. 작업장 내 안전 시설물(예: 안전 램프, 비상구 등)을',\n",
       " \"### 답변:\\n안전발판 전 수리작업 실시, 작업절차 개정 및 교육 실시, 정기적 안전검사 강화, 작업자별 안전성적평가 실시, 안전관리체계 개선 및 정기적 검토.\\n\\n위 사고의 원인인 '안\",\n",
       " '### 답변:\\n1. 작업자 교육 강화: 작업자의 안전 의식을 높이기 위해 정기적인 안전 교육을 실시하고, 사고 원인에 대한 심층 이해를 도모해야 합니다.\\n2. 작업 환경 개선: 작업장 내 안전 표지판 설치, 작업 공간 정리',\n",
       " '### 답변:\\n1. TSC GIRDER 조립 시 SPLICE PLATE 설치 작업의 위험성 평가 실시.\\n2. 작업장비 사용자 교육 강화: 안전장비 착용, 적절한 작업 자세, 안전 거리 유지 등.\\n3. 작업장 내 안전시설 개선',\n",
       " '### 답변:\\n\\n안전사고 재발 방지를 위해 다음과 같은 대책을 제안합니다:\\n\\n1. 작업장 내 안전 미비요인 제거: 작업장 내 위험 요인을 철저히 점검하고 제거해야 합니다. 특히 작업대 주변의 각재 배치와 작업',\n",
       " '### 답변:\\n해체 작업 중 안전사고 발생을 최소화하기 위해 다음과 같은 재발 방지 대책과 향후 조치 계획을 제안합니다:\\n\\n1. 작업 전 안전점검 강화: 모든 해체 작업 전 사전 안전점검을 철저히 실시하여 잠재']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae869742-4a0b-45bc-8a50-e385b67a9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "# 최종 결과 저장\n",
    "# submission.iloc[:,1] = test_results\n",
    "# submission.iloc[:,2:] = pred_embeddings\n",
    "submission.iloc[:10,1] = test_results\n",
    "submission.iloc[:10,2:] = pred_embeddings\n",
    "submission.head()\n",
    "\n",
    "# 최종 결과를 CSV로 저장\n",
    "submission.to_csv('./baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
