{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID                                           question\n",
      "33468   TRAIN_06702      ìš´ìˆ˜ì‹œì„¤ / ì™¸ë¶€ì—ì„œ ì„¤ì¹˜ì‘ì—… ì¤‘ ê±´ì„¤ìì¬ > ìì¬ë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\n",
      "19482   TRAIN_03896   ì—…ë¬´ì‹œì„¤ / ì™¸ë¶€ì—ì„œ í˜•í‹€ ë° ëª©ê³µ ì¤‘ ê±´ì„¤ìì¬ > ì² ê·¼ë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\n",
      "34343   TRAIN_06878  2022-11-14 ì˜¤ì „ 11:50ì— ë§‘ìŒ ìƒíƒœì—ì„œ 10â„ƒë„, ìŠµë„ 30%% í™˜ê²½ì—...\n",
      "48275   TRAIN_09669   ê³µë™ì£¼íƒ / ì™¸ë¶€ì—ì„œ ìš´ë°˜ì‘ì—… ì¤‘ ê±´ì„¤ê¸°ê³„ > íƒ€ì›Œí¬ë ˆì¸ë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\n",
      "108585  TRAIN_21830                  ì‚¬ë‹¤ë¦¬ ì‘ì—… ì¤‘ ë¶€ì£¼ì˜ìœ¼ë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì˜ˆë°© ëŒ€ì±…ì€?\n",
      "67537   TRAIN_13523  ê³µë™ì£¼íƒ / ë‚´ë¶€ì—ì„œ í˜•í‹€ ë° ëª©ê³µ ì¤‘ ê±´ì„¤ê³µêµ¬ > ê³µêµ¬ë¥˜ë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\n",
      "12543   TRAIN_02508      í•˜ìˆ˜ë„ / ë‚´ë¶€ì—ì„œ êµ´ì°©ì‘ì—… ì¤‘ ê¸°íƒ€ > ì§€í•˜ë§¤ì„¤ë¬¼ë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\n",
      "50490   TRAIN_10112     ì—…ë¬´ì‹œì„¤ / ë‚´ë¶€ì—ì„œ ì„¤ì¹˜ì‘ì—… ì¤‘ ê°€ì‹œì„¤ > ì‘ì—…ë°œíŒë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\n",
      "60819   TRAIN_12178      ê³µë™ì£¼íƒ / ë‚´ë¶€ì—ì„œ ì„¤ì¹˜ì‘ì—… ì¤‘ ê±´ì„¤ìì¬ > ìì¬ë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\n",
      "35865   TRAIN_07182  ì§€í•˜ì£¼ì°¨ì¥ìœ¼ë¡œ ìì¬ë¥¼ í•˜ì—­ì¤‘ íƒ€ì›Œí¬ë ˆì¸ìœ¼ë¡œ ìì¬ë¥¼ ë°›ê¸°ìœ„í•´ ì´ë™ì¤‘ ë°˜ì¶œì¤‘ì¸ í†¤ë§ˆëŒ€ì—...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "file_path = \"../../data/train.csv\"  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ğŸ“Œ ì§ˆë¬¸ì§€ ìƒì„± í•¨ìˆ˜\n",
    "def generate_questions(row):\n",
    "    questions = []\n",
    "\n",
    "    # 1ï¸âƒ£ ì‚¬ê³  ë°œìƒ ìƒí™© ê¸°ë°˜ ì§ˆë¬¸\n",
    "    if pd.notna(row[\"ë°œìƒì¼ì‹œ\"]) and pd.notna(row[\"ë‚ ì”¨\"]) and pd.notna(row[\"ê¸°ì˜¨\"]) and pd.notna(row[\"ìŠµë„\"]):\n",
    "        questions.append(\n",
    "            f\"{row['ë°œìƒì¼ì‹œ']}ì— {row['ë‚ ì”¨']} ìƒíƒœì—ì„œ {row['ê¸°ì˜¨']}ë„, ìŠµë„ {row['ìŠµë„']}% í™˜ê²½ì—ì„œ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\"\n",
    "        )\n",
    "\n",
    "    # 2ï¸âƒ£ ê³µì‚¬ ê´€ë ¨ ì§ˆë¬¸\n",
    "    if pd.notna(row[\"ê³µì‚¬ì¢…ë¥˜\"]) and pd.notna(row[\"ì—°ë©´ì \"]) and pd.notna(row[\"ì¸µ ì •ë³´\"]):\n",
    "        questions.append(\n",
    "            f\"{row['ê³µì‚¬ì¢…ë¥˜']}ì—ì„œ ì—°ë©´ì  {row['ì—°ë©´ì ']}ã¡, {row['ì¸µ ì •ë³´']}ì¸µì—ì„œ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\"\n",
    "        )\n",
    "\n",
    "    # 3ï¸âƒ£ ì‚¬ê³  ìœ í˜• ê¸°ë°˜ ì§ˆë¬¸\n",
    "    if pd.notna(row[\"ì¸ì ì‚¬ê³ \"]) or pd.notna(row[\"ë¬¼ì ì‚¬ê³ \"]):\n",
    "        accident_desc = []\n",
    "        if pd.notna(row[\"ì¸ì ì‚¬ê³ \"]):\n",
    "            accident_desc.append(f\"ì¸ì ì‚¬ê³ ({row['ì¸ì ì‚¬ê³ ']})\")\n",
    "        if pd.notna(row[\"ë¬¼ì ì‚¬ê³ \"]):\n",
    "            accident_desc.append(f\"ë¬¼ì ì‚¬ê³ ({row['ë¬¼ì ì‚¬ê³ ']})\")\n",
    "        questions.append(\n",
    "            f\"{' ë° '.join(accident_desc)}ê°€ ë°œìƒí•œ ì‚¬ê³ ì—ì„œì˜ ëŒ€ì‘ ë°©ì•ˆì€?\"\n",
    "        )\n",
    "\n",
    "    # 4ï¸âƒ£ ì‘ì—… í”„ë¡œì„¸ìŠ¤ ê´€ë ¨ ì§ˆë¬¸\n",
    "    if pd.notna(row[\"ì‘ì—…í”„ë¡œì„¸ìŠ¤\"]) and pd.notna(row[\"ì‚¬ê³ ê°ì²´\"]) and pd.notna(row[\"ì¥ì†Œ\"]):\n",
    "        questions.append(\n",
    "            f\"{row['ì¥ì†Œ']}ì—ì„œ {row['ì‘ì—…í”„ë¡œì„¸ìŠ¤']} ì¤‘ {row['ì‚¬ê³ ê°ì²´']}ë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì›ì¸ì€?\"\n",
    "        )\n",
    "\n",
    "    # 5ï¸âƒ£ ì‚¬ê³ ì›ì¸ ê¸°ë°˜ ì§ˆë¬¸\n",
    "    if pd.notna(row[\"ì‚¬ê³ ì›ì¸\"]):\n",
    "        questions.append(\n",
    "            f\"{row['ì‚¬ê³ ì›ì¸']}ìœ¼ë¡œ ì¸í•´ ë°œìƒí•œ ì‚¬ê³ ì˜ ì˜ˆë°© ëŒ€ì±…ì€?\"\n",
    "        )\n",
    "\n",
    "    return questions\n",
    "\n",
    "# ğŸ“Œ ì§ˆë¬¸ì§€ ìƒì„±\n",
    "question_data = []\n",
    "for _, row in df.iterrows():\n",
    "    questions = generate_questions(row)\n",
    "    for question in questions:\n",
    "        question_data.append({\"ID\": row[\"ID\"], \"question\": question})\n",
    "\n",
    "# DataFrame ìƒì„±\n",
    "question_df = pd.DataFrame(question_data)\n",
    "\n",
    "# ğŸ“Œ ëœë¤ ìƒ˜í”Œ 10ê°œ ì¶œë ¥\n",
    "print(question_df.sample(10))\n",
    "\n",
    "# CSVë¡œ ì €ì¥ (ì¶”í›„ RAG ì…ë ¥ ë°ì´í„°ë¡œ í™œìš© ê°€ëŠ¥)\n",
    "# output_path = \"data/generated_questions.csv\"\n",
    "# question_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# print(f\"âœ… ì§ˆë¬¸ì§€ ìƒì„± ì™„ë£Œ â†’ {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'í…ŒìŠ¤íŠ¸ ', '2': '\\n\\n langchainì´ë€? '}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'í…ŒìŠ¤íŠ¸ - 1 -\\n\\n langchainì´ë€? - 2 -'\n",
    "\n",
    "def page_split(content):\n",
    "    '''pageë³„ë¡œ ìª¼ê°œë²„ë¦¼'''\n",
    "    page_dict = {}\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        contents = content.split(f\"- {i} -\")\n",
    "        if len(contents) != 2:\n",
    "            break\n",
    "        page_dict[str(i)] = contents[0]\n",
    "        content = contents[1]\n",
    "    return page_dict\n",
    "\n",
    "page_split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['í…ŒìŠ¤íŠ¸ ', '1', '\\n\\n langchainì´ë€? ', '2', '']\n",
      "{'1': 'í…ŒìŠ¤íŠ¸ ', '2': '\\n\\n langchainì´ë€? '}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "tmp = re.split(r\"-\\s(\\d+)\\s-\", text)\n",
    "print(tmp)\n",
    "result = {tmp[i]: tmp[i-1] for i in range(1, len(tmp)-1, 2)}\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
